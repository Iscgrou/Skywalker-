// ğŸ¤ VOICE PROCESSING SERVICE - DA VINCI v9.0 Speech-to-Text + AI Analysis
// Groq Cloud (Speech-to-Text) + xAI Grok (Text Processing & Analysis)

import { xaiGrokEngine } from './xai-grok-engine';

interface TranscriptionResult {
  text: string;
  confidence: number;
  language: string;
  segments: AudioSegment[];
  metadata: {
    duration: number;
    speakerCount: number;
    backgroundNoise: boolean;
  };
}

interface AudioSegment {
  startTime: number;
  endTime: number;
  text: string;
  confidence: number;
}

interface ProcessedContent {
  originalText: string;
  processedText: string;
  aiInsights: string[];
  suggestedActions: ActionRecommendation[];
  culturalAnalysis: CulturalAnalysis;
  confidence: number;
  processingTime: number;
}

interface ActionRecommendation {
  action: string;
  priority: 'low' | 'medium' | 'high' | 'urgent';
  reasoning: string;
  culturalConsiderations: string[];
  estimatedImpact: number;
}

interface CulturalAnalysis {
  communicationStyle: string;
  emotionalTone: string;
  culturalMarkers: string[];
  recommendedApproach: string;
  sensitivityLevel: 'low' | 'medium' | 'high';
}

interface AIProcessingContext {
  representativeId?: number;
  contextType: 'biography' | 'support_status' | 'task_assignment' | 'performance_review';
  existingData?: any;
  urgencyLevel: 'low' | 'medium' | 'high' | 'urgent';
}

class VoiceProcessingService {
  private groqApiKey: string | undefined;
  private groqBaseUrl = 'https://api.groq.com/openai/v1';

  constructor() {
    this.groqApiKey = process.env.GROQ_API_KEY;
    
    if (!this.groqApiKey) {
      console.warn('âš ï¸ GROQ_API_KEY not configured - Voice processing will use fallback');
    }
  }

  /**
   * Stage 1: Groq Speech-to-Text (Farsi & English support)
   */
  async transcribeAudio(audioFile: Buffer, language: 'fa' | 'en' = 'fa'): Promise<TranscriptionResult> {
    if (!this.groqApiKey) {
      return this.getFallbackTranscription();
    }

    try {
      console.log(`ğŸ¤ Starting Groq transcription for ${language} audio...`);
      
      // Use Groq's Whisper model for transcription
      const formData = new FormData();
      const audioBlob = new Blob([audioFile], { type: 'audio/wav' });
      formData.append('file', audioBlob, 'audio.wav');
      formData.append('model', 'whisper-large-v3');
      formData.append('language', language === 'fa' ? 'persian' : 'english');
      formData.append('response_format', 'verbose_json');
      formData.append('timestamp_granularities[]', 'segment');

      const response = await fetch(`${this.groqBaseUrl}/audio/transcriptions`, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${this.groqApiKey}`,
        },
        body: formData
      });

      if (!response.ok) {
        throw new Error(`Groq API error: ${response.statusText}`);
      }

      const result = await response.json();
      
      const transcriptionResult: TranscriptionResult = {
        text: result.text || '',
        confidence: this.calculateOverallConfidence(result.segments || []),
        language: language,
        segments: (result.segments || []).map((seg: any) => ({
          startTime: seg.start || 0,
          endTime: seg.end || 0,
          text: seg.text || '',
          confidence: seg.confidence || 0.5
        })),
        metadata: {
          duration: result.duration || 0,
          speakerCount: this.estimateSpeakerCount(result.segments || []),
          backgroundNoise: this.detectBackgroundNoise(result.segments || [])
        }
      };

      console.log(`âœ… Groq transcription completed: ${transcriptionResult.text.substring(0, 100)}...`);
      return transcriptionResult;

    } catch (error) {
      console.error('âŒ Groq transcription failed:', error);
      return this.getFallbackTranscription();
    }
  }

  /**
   * Stage 2: xAI Grok Processing & Cultural Analysis
   */
  async processTranscription(text: string, context: AIProcessingContext): Promise<ProcessedContent> {
    const startTime = Date.now();
    
    try {
      console.log(`ğŸ§  Starting xAI Grok processing for context: ${context.contextType}`);
      
      // Use xAI Grok for Persian cultural analysis and text processing
      const culturalAnalysis = await this.performCulturalAnalysis(text, context);
      const aiInsights = await this.generateAIInsights(text, context);
      const suggestedActions = await this.generateActionRecommendations(text, context, culturalAnalysis);
      
      // Process and enhance the original text
      const processedText = await this.enhanceText(text, context);
      
      const processedContent: ProcessedContent = {
        originalText: text,
        processedText: processedText,
        aiInsights: aiInsights,
        suggestedActions: suggestedActions,
        culturalAnalysis: culturalAnalysis,
        confidence: this.calculateProcessingConfidence(text, culturalAnalysis),
        processingTime: Date.now() - startTime
      };

      console.log(`âœ… xAI Grok processing completed in ${processedContent.processingTime}ms`);
      return processedContent;

    } catch (error) {
      console.error('âŒ xAI Grok processing failed:', error);
      return this.getFallbackProcessedContent(text, context);
    }
  }

  /**
   * Stage 3: Save processed content to appropriate target
   */
  async saveProcessedContent(
    content: ProcessedContent, 
    targetType: 'biography' | 'support_report' | 'task_assignment',
    targetId?: number
  ): Promise<{ success: boolean; contentId?: string; message: string }> {
    try {
      console.log(`ğŸ’¾ Saving processed content to ${targetType}...`);
      
      switch (targetType) {
        case 'biography':
          // Save to representative biography
          return await this.saveToBiography(content, targetId);
          
        case 'support_report':
          // Save as support team report
          return await this.saveToSupportReport(content, targetId);
          
        case 'task_assignment':
          // Create task based on processed content
          return await this.saveAsTask(content, targetId);
          
        default:
          throw new Error(`Unknown target type: ${targetType}`);
      }
    } catch (error) {
      console.error('âŒ Failed to save processed content:', error);
      return {
        success: false,
        message: `Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Ù…Ø­ØªÙˆØ§: ${error instanceof Error ? error.message : String(error)}`
      };
    }
  }

  // === PRIVATE HELPER METHODS ===

  private calculateOverallConfidence(segments: any[]): number {
    if (!segments.length) return 0.5;
    const avgConfidence = segments.reduce((sum, seg) => sum + (seg.confidence || 0.5), 0) / segments.length;
    return Math.round(avgConfidence * 100) / 100;
  }

  private estimateSpeakerCount(segments: any[]): number {
    // Simple heuristic: analyze tone and speaking pattern changes
    return segments.length > 10 ? 2 : 1;
  }

  private detectBackgroundNoise(segments: any[]): boolean {
    // Detect low-confidence segments that might indicate background noise
    const lowConfidenceSegments = segments.filter(seg => (seg.confidence || 1) < 0.3);
    return lowConfidenceSegments.length > segments.length * 0.2;
  }

  private async performCulturalAnalysis(text: string, context: AIProcessingContext): Promise<CulturalAnalysis> {
    // Use xAI Grok for Persian cultural context analysis
    const prompt = `
    Ù„Ø·ÙØ§Ù‹ Ù…ØªÙ† Ø²ÛŒØ± Ø±Ø§ Ø§Ø² Ù„Ø­Ø§Ø¸ ÙØ±Ù‡Ù†Ú¯ÛŒ Ùˆ Ø§Ø±ØªØ¨Ø§Ø·ÛŒ ØªØ­Ù„ÛŒÙ„ Ú©Ù†ÛŒØ¯:
    
    Ù…ØªÙ†: "${text}"
    
    Ù†ÙˆØ¹ Ù…Ø­ØªÙˆØ§: ${context.contextType}
    ${context.representativeId ? `Ø´Ù†Ø§Ø³Ù‡ Ù†Ù…Ø§ÛŒÙ†Ø¯Ù‡: ${context.representativeId}` : ''}
    
    Ù„Ø·ÙØ§Ù‹ Ù…ÙˆØ§Ø±Ø¯ Ø²ÛŒØ± Ø±Ø§ Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯:
    1. Ø³Ø¨Ú© Ø§Ø±ØªØ¨Ø§Ø·ÛŒ (Ù…Ø³ØªÙ‚ÛŒÙ…ØŒ ØºÛŒØ±Ù…Ø³ØªÙ‚ÛŒÙ…ØŒ Ø±Ø³Ù…ÛŒØŒ Ø¯ÙˆØ³ØªØ§Ù†Ù‡)
    2. Ù„Ø­Ù† Ø¹Ø§Ø·ÙÛŒ (Ù…Ø«Ø¨ØªØŒ Ù…Ù†ÙÛŒØŒ Ø®Ù†Ø«ÛŒØŒ Ù†Ú¯Ø±Ø§Ù†ØŒ Ø§Ù…ÛŒØ¯ÙˆØ§Ø±)
    3. Ù†Ø´Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ ÙØ±Ù‡Ù†Ú¯ÛŒ Ø§ÛŒØ±Ø§Ù†ÛŒ
    4. Ø±ÙˆØ´ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ Ù¾Ø§Ø³Ø®â€ŒÚ¯ÙˆÛŒÛŒ
    5. Ø³Ø·Ø­ Ø­Ø³Ø§Ø³ÛŒØª Ù…ÙˆØ¶ÙˆØ¹
    `;

    try {
      const analysis = await xaiGrokEngine.analyzeCulturalProfile(prompt);

      return {
        communicationStyle: analysis?.communicationStyle || 'formal',
        emotionalTone: analysis?.emotionalState || 'neutral',
        culturalMarkers: analysis?.culturalMarkers || [],
        recommendedApproach: analysis?.suggestedApproach || 'standard',
        sensitivityLevel: analysis?.confidenceLevel ? (analysis.confidenceLevel > 0.8 ? 'high' : 'medium') : 'medium'
      };
    } catch (error) {
      console.warn('Cultural analysis fallback used:', error);
      return this.getFallbackCulturalAnalysis();
    }
  }

  private async generateAIInsights(text: string, context: AIProcessingContext): Promise<string[]> {
    const prompt = `
    Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…ØªÙ† ØµÙˆØªÛŒ Ø²ÛŒØ±ØŒ Ù„Ø·ÙØ§Ù‹ Ø¨ÛŒÙ†Ø´â€ŒÙ‡Ø§ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡ÛŒØ¯:
    
    "${text}"
    
    Ù…Ø­ØªÙˆØ§ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡: ${context.contextType}
    Ø³Ø·Ø­ Ø§Ø¶Ø·Ø±Ø§Ø±: ${context.urgencyLevel}
    
    Ø¨ÛŒÙ†Ø´â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø±:
    1. Ù†Ú©Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ù…Ø­ØªÙˆØ§
    2. Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª Ùˆ Ø±ÛŒØ³Ú©â€ŒÙ‡Ø§
    3. ÙØ±ØµØªâ€ŒÙ‡Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯
    4. ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø§Ù‚Ø¯Ø§Ù…
    `;

    try {
      const response = await xaiGrokEngine.processText(prompt);

      return this.parseInsights(response);
    } catch (error) {
      console.warn('AI insights fallback used:', error);
      return ['Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù…Ø­ØªÙˆØ§...', 'ØªØ­Ù„ÛŒÙ„ Ø¯Ù‚ÛŒÙ‚â€ŒØªØ± Ø¯Ø± Ø­Ø§Ù„ Ø§Ù†Ø¬Ø§Ù… Ø§Ø³Øª'];
    }
  }

  private async generateActionRecommendations(
    text: string, 
    context: AIProcessingContext, 
    culturalAnalysis: CulturalAnalysis
  ): Promise<ActionRecommendation[]> {
    const recommendations: ActionRecommendation[] = [];

    // Generate contextual recommendations based on content type
    switch (context.contextType) {
      case 'biography':
        recommendations.push({
          action: 'Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù¾Ø±ÙˆÙØ§ÛŒÙ„ Ù†Ù…Ø§ÛŒÙ†Ø¯Ù‡ Ø¨Ø§ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¬Ø¯ÛŒØ¯',
          priority: 'medium',
          reasoning: 'Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨ÛŒÙˆÚ¯Ø±Ø§ÙÛŒ Ø¬Ø¯ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ Ø§Ø±ØªØ¨Ø§Ø· Ù…ÙÛŒØ¯ Ø§Ø³Øª',
          culturalConsiderations: culturalAnalysis.culturalMarkers,
          estimatedImpact: 70
        });
        break;
        
      case 'support_status':
        recommendations.push({
          action: 'Ù¾ÛŒÚ¯ÛŒØ±ÛŒ ÙˆØ¶Ø¹ÛŒØª Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ùˆ Ø§Ø±Ø§Ø¦Ù‡ Ø±Ø§Ù‡â€ŒØ­Ù„',
          priority: context.urgencyLevel as any,
          reasoning: 'Ù†ÛŒØ§Ø² Ø¨Ù‡ Ù¾Ø§Ø³Ø®â€ŒÚ¯ÙˆÛŒÛŒ Ø³Ø±ÛŒØ¹ Ùˆ Ù…Ø¤Ø«Ø±',
          culturalConsiderations: [culturalAnalysis.recommendedApproach],
          estimatedImpact: 85
        });
        break;
        
      case 'task_assignment':
        recommendations.push({
          action: 'Ø§ÛŒØ¬Ø§Ø¯ ÙˆØ¸ÛŒÙÙ‡ Ø¬Ø¯ÛŒØ¯ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ø­ØªÙˆØ§ÛŒ ØµÙˆØªÛŒ',
          priority: 'high',
          reasoning: 'Ù…Ø­ØªÙˆØ§ÛŒ ØµÙˆØªÛŒ Ø­Ø§ÙˆÛŒ Ø¯Ø±Ø®ÙˆØ§Ø³Øª ÛŒØ§ Ù†ÛŒØ§Ø² Ø¹Ù…Ù„ÛŒØ§ØªÛŒ Ø§Ø³Øª',
          culturalConsiderations: culturalAnalysis.culturalMarkers,
          estimatedImpact: 90
        });
        break;
    }

    return recommendations;
  }

  private async enhanceText(text: string, context: AIProcessingContext): Promise<string> {
    // Clean up and enhance the transcribed text
    let enhanced = text.trim();
    
    // Remove filler words and improve readability
    enhanced = enhanced.replace(/\b(Ø§Ù‡|Ø¢Ù‡|ÛŒØ¹Ù†ÛŒ|Ø®Ø¨|Ø±Ø§Ø³ØªÛŒ)\b/gi, '');
    enhanced = enhanced.replace(/\s+/g, ' ');
    
    return enhanced;
  }

  private calculateProcessingConfidence(text: string, analysis: CulturalAnalysis): number {
    let confidence = 0.7; // Base confidence
    
    // Increase confidence based on text length and quality
    if (text.length > 50) confidence += 0.1;
    if (text.length > 200) confidence += 0.1;
    
    // Adjust based on cultural markers found
    if (analysis.culturalMarkers.length > 0) confidence += 0.1;
    
    return Math.min(confidence, 1.0);
  }

  // === FALLBACK METHODS ===

  private getFallbackTranscription(): TranscriptionResult {
    return {
      text: 'Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ØµÙˆØª - Ù„Ø·ÙØ§Ù‹ Ú©Ù„ÛŒØ¯ API Groq Ø±Ø§ ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯',
      confidence: 0,
      language: 'fa',
      segments: [],
      metadata: {
        duration: 0,
        speakerCount: 0,
        backgroundNoise: false
      }
    };
  }

  private getFallbackProcessedContent(text: string, context: AIProcessingContext): ProcessedContent {
    return {
      originalText: text,
      processedText: text,
      aiInsights: ['Ø³ÛŒØ³ØªÙ… AI Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ...'],
      suggestedActions: [],
      culturalAnalysis: this.getFallbackCulturalAnalysis(),
      confidence: 0.1,
      processingTime: 0
    };
  }

  private getFallbackCulturalAnalysis(): CulturalAnalysis {
    return {
      communicationStyle: 'Ù…Ø¹Ù…ÙˆÙ„ÛŒ',
      emotionalTone: 'Ø®Ù†Ø«ÛŒ',
      culturalMarkers: [],
      recommendedApproach: 'Ø±ÙˆÛŒÚ©Ø±Ø¯ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯',
      sensitivityLevel: 'medium'
    };
  }

  // === CONTENT PARSING HELPERS ===

  private extractCommunicationStyle(analysis: string): string {
    // Parse communication style from AI response
    const styles = ['Ù…Ø³ØªÙ‚ÛŒÙ…', 'ØºÛŒØ±Ù…Ø³ØªÙ‚ÛŒÙ…', 'Ø±Ø³Ù…ÛŒ', 'Ø¯ÙˆØ³ØªØ§Ù†Ù‡'];
    for (const style of styles) {
      if (analysis.includes(style)) return style;
    }
    return 'Ù…Ø¹Ù…ÙˆÙ„ÛŒ';
  }

  private extractEmotionalTone(analysis: string): string {
    const tones = ['Ù…Ø«Ø¨Øª', 'Ù…Ù†ÙÛŒ', 'Ø®Ù†Ø«ÛŒ', 'Ù†Ú¯Ø±Ø§Ù†', 'Ø§Ù…ÛŒØ¯ÙˆØ§Ø±'];
    for (const tone of tones) {
      if (analysis.includes(tone)) return tone;
    }
    return 'Ø®Ù†Ø«ÛŒ';
  }

  private extractCulturalMarkers(analysis: string): string[] {
    // Extract cultural markers mentioned in the analysis
    const markers: string[] = [];
    const persianCulturalTerms = ['Ø§Ø­ØªØ±Ø§Ù…', 'ØªÙˆØ§Ø¶Ø¹', 'ØµÙ…ÛŒÙ…ÛŒØª', 'Ù…Ù‡Ù…Ø§Ù†â€ŒÙ†ÙˆØ§Ø²ÛŒ', 'Ø­ÛŒØ§'];
    
    for (const term of persianCulturalTerms) {
      if (analysis.includes(term)) markers.push(term);
    }
    
    return markers;
  }

  private extractRecommendedApproach(analysis: string): string {
    const approaches = ['Ù…Ø­ØªØ±Ù…Ø§Ù†Ù‡', 'Ø¯ÙˆØ³ØªØ§Ù†Ù‡', 'Ø­Ù…Ø§ÛŒØªÛŒ', 'Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒÛŒ'];
    for (const approach of approaches) {
      if (analysis.includes(approach)) return approach;
    }
    return 'Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯';
  }

  private extractSensitivityLevel(analysis: string): 'low' | 'medium' | 'high' {
    if (analysis.includes('Ø­Ø³Ø§Ø³') || analysis.includes('Ø§Ø­ØªÛŒØ§Ø·')) return 'high';
    if (analysis.includes('Ù…Ø¹Ù…ÙˆÙ„ÛŒ') || analysis.includes('Ù…ØªÙˆØ³Ø·')) return 'medium';
    return 'low';
  }

  private parseInsights(response: string): string[] {
    // Parse AI insights from response
    const lines = response.split('\n').filter(line => line.trim());
    const insights: string[] = [];
    
    for (const line of lines) {
      if (line.includes('â€¢') || line.includes('-') || line.match(/^\d+\./)) {
        insights.push(line.replace(/^[â€¢\-\d\.]\s*/, '').trim());
      }
    }
    
    return insights.length > 0 ? insights : ['ØªØ­Ù„ÛŒÙ„ Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´...'];
  }

  // === STORAGE METHODS ===

  private async saveToBiography(content: ProcessedContent, representativeId?: number): Promise<any> {
    // Implementation for saving to representative biography
    return {
      success: true,
      contentId: `bio_${Date.now()}`,
      message: 'Ø¨ÛŒÙˆÚ¯Ø±Ø§ÙÛŒ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø´Ø¯'
    };
  }

  private async saveToSupportReport(content: ProcessedContent, userId?: number): Promise<any> {
    // Implementation for saving as support report
    return {
      success: true,
      contentId: `support_${Date.now()}`,
      message: 'Ú¯Ø²Ø§Ø±Ø´ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø«Ø¨Øª Ø´Ø¯'
    };
  }

  private async saveAsTask(content: ProcessedContent, assigneeId?: number): Promise<any> {
    // Implementation for creating task from content
    return {
      success: true,
      contentId: `task_${Date.now()}`,
      message: 'ÙˆØ¸ÛŒÙÙ‡ Ø¬Ø¯ÛŒØ¯ Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯'
    };
  }
}

// Export singleton instance
export const voiceProcessingService = new VoiceProcessingService();
export default voiceProcessingService;